{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12aff38c-23eb-4640-8cf0-cefd8c7c51e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from dataclasses import field\n",
    "from typing import Any\n",
    "import jax\n",
    "import numpy as np\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state\n",
    "from jax import numpy as jnp\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432a2621-f1d4-4100-8074-df66970952e4",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bb13b4e-7338-4175-b434-2ab736e568f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def of_class(Class):\n",
    "    \"\"\"Register functions as methods in created class.\"\"\"\n",
    "    def wrapper(obj):\n",
    "        setattr(Class, obj.__name__, obj)\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb4f58ef-c93e-4077-98e5-471908034830",
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    def __init__(self):\n",
    "        self.b = 1\n",
    "\n",
    "a = A()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffb73894-f9bf-453f-a21e-197729d81c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class attribute \"b\" is 1\n"
     ]
    }
   ],
   "source": [
    "@of_class(A)\n",
    "def do(self):\n",
    "    print('Class attribute \"b\" is', self.b)\n",
    "\n",
    "a.do()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58eaa40a-6d8a-47c0-a814-d5f13510d059",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperParameters:\n",
    "    def save_hyperparameters(self, ignore=[]):\n",
    "        frame = inspect.currentframe().f_back\n",
    "        _, _, _, local_vars = inspect.getargvalues(frame)\n",
    "        self.hparams = {k:v for k, v in local_vars.items()\n",
    "                    if k not in set(ignore+['self']) and not k.startswith('_')}\n",
    "        for k, v in self.hparams.items():\n",
    "            setattr(self, k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "088c193c-17f2-4e1c-ae82-9d28307b2eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.a= 1 self.b 2\n",
      "There is no self.c= True\n"
     ]
    }
   ],
   "source": [
    "class B(HyperParameters):\n",
    "    def __init__(self, a, b, c):\n",
    "        self.save_hyperparameters(ignore=['c'])\n",
    "        print('self.a=', self.a, 'self.b', self.b)\n",
    "        print('There is no self.c=', not hasattr(self, 'c'))\n",
    "\n",
    "b = B(a=1, b=2, c=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2633ad-f819-444a-adda-662e34545487",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "643df7e6-feff-4e8d-9e88-286d1dbd2c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module(nn.Module, HyperParameters):\n",
    "    plot_train_per_epoch: int = field(default=2, init=False)\n",
    "    plot_valid_per_epoch: int = field(default=1, init=False)\n",
    "\n",
    "    def loss(self, y_hat, y):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def forward(self, X, *args, **kwargs):\n",
    "        assert hasattr(self, 'net'), 'Neural network is defined'\n",
    "        return self.net(X, *args, **kwargs)\n",
    "\n",
    "    def __call__(self, X, *args, **kwargs):\n",
    "        return self.forwarrd(X, *args, *kwargs)\n",
    "\n",
    "    def plot(self, key, value, train):\n",
    "        assert hasattr(self, 'trainer'), 'Trainer is not inited'\n",
    "        self.board.xlabel = 'epoch'\n",
    "        if train:\n",
    "            x = self.trainer.train_batch_idx / self.trainer.num_train_batches\n",
    "            n = self.trainer_num_batches / self.plot_train_per_epoch\n",
    "        else:\n",
    "            x = self.train.epoch + 1\n",
    "            n = self.trainer.num_val_batches / self.plot_valid_per_epoch\n",
    "        self.board.draw(x, value, ('train' if train else 'val_') + key, every_n=int(n))\n",
    "\n",
    "    def training_step(self, params, batch, state):\n",
    "        l, grads = jax.value_and_grad(self.loss)(params, batch[:-1], batch[-1], state)\n",
    "\n",
    "        self.plot(\"loss\", l, train=True)\n",
    "        return l, grads\n",
    "\n",
    "    def validation_step(self, params, batch, state):\n",
    "        l = self.loss(params, batch[:-1], batch[-1], state)\n",
    "        self.plot('loss', l, train=False)\n",
    "\n",
    "    def apply_iniy(self, dummy_input, key):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1b2c63-9780-4916-bcdb-e517722c156f",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92febe42-6aa9-4ef5-a6c6-eedb569106c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(HyperParameters):\n",
    "    def __init__(self, root='../data'):\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def get_dataloader(self, train):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self.get_dataloader(train=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.get_dataloader(train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8330caad-f2d4-46bc-bbcb-21cf2c1ed202",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79db1b4b-938e-4fd5-bea9-752cb1ff6fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(HyperParameters):  #@save\n",
    "    \"\"\"The base class for training models with data.\"\"\"\n",
    "    def __init__(self, max_epochs, num_gpus=0, gradient_clip_val=0):\n",
    "        self.save_hyperparameters()\n",
    "        assert num_gpus == 0, 'No GPU support yet'\n",
    "\n",
    "    def prepare_data(self, data):\n",
    "        self.train_dataloader = data.train_dataloader()\n",
    "        self.val_dataloader = data.val_dataloader()\n",
    "        self.num_train_batches = len(self.train_dataloader)\n",
    "        self.num_val_batches = (len(self.val_dataloader)\n",
    "                                if self.val_dataloader is not None else 0)\n",
    "\n",
    "    def prepare_model(self, model):\n",
    "        model.trainer = self\n",
    "        model.board.xlim = [0, self.max_epochs]\n",
    "        self.model = model\n",
    "\n",
    "    def fit(self, model, data, key=None):\n",
    "        self.prepare_data(data)\n",
    "        self.prepare_model(model)\n",
    "        self.optim = model.configure_optimizers()\n",
    "\n",
    "        if key is None:\n",
    "            root_key = d2l.get_key()\n",
    "        else:\n",
    "            root_key = key\n",
    "        params_key, dropout_key = jax.random.split(root_key)\n",
    "        key = {'params': params_key, 'dropout': dropout_key}\n",
    "\n",
    "        dummy_input = next(iter(self.train_dataloader))[:-1]\n",
    "        variables = model.apply_init(dummy_input, key=key)\n",
    "        params = variables['params']\n",
    "\n",
    "        if 'batch_stats' in variables.keys():\n",
    "            # Here batch_stats will be used later (e.g., for batch norm)\n",
    "            batch_stats = variables['batch_stats']\n",
    "        else:\n",
    "            batch_stats = {}\n",
    "\n",
    "        # Flax uses optax under the hood for a single state obj TrainState.\n",
    "        # More will be discussed later in the dropout and batch\n",
    "        # normalization section\n",
    "        class TrainState(train_state.TrainState):\n",
    "            batch_stats: Any\n",
    "            dropout_rng: jax.random.PRNGKeyArray\n",
    "\n",
    "        self.state = TrainState.create(apply_fn=model.apply,\n",
    "                                       params=params,\n",
    "                                       batch_stats=batch_stats,\n",
    "                                       dropout_rng=dropout_key,\n",
    "                                       tx=model.configure_optimizers())\n",
    "        self.epoch = 0\n",
    "        self.train_batch_idx = 0\n",
    "        self.val_batch_idx = 0\n",
    "        for self.epoch in range(self.max_epochs):\n",
    "            self.fit_epoch()\n",
    "\n",
    "    def fit_epoch(self):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bfbede-fb73-43c6-ad38-7871ca380e67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
